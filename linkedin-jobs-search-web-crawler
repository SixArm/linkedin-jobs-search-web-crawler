#!/usr/bin/env python3

##
# LinkedIn jobs search web crawler
#
# Syntax:
#
#     linkedin-jobs-search-web-crawler [options]
#
# Example of a search query:
#
#     linkedin-jobs-search-web-crawler --query "keywords=programmer"
#
# Example result URL:
#
#     https://www.linkedin.com/jobs/search?keywords=programmer
#
# Example of a search with "for time posted within 1 day":
#
#     linkedin-jobs-search-web-crawler --query "keywords=programmer&f_TP=1"
#
# Example URL of a result:
#
#     https://www.linkedin.com/jobs/search?currentJobId=100000000
#
# Example URL of an API call that also works incognito:
#
#     https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/100000000
#
# Based on work by:
#
#     https://www.linkedin.com/pulse/how-easy-scraping-data-from-linkedin-profiles-david-craven/
#
#
# ## Setup
#
#
# Preflight:
#
# ```sh
# pip3 install csv
# pip3 install ipython
# pip3 install numpy
# pip3 install parsel
# pip3 install selenium
# pip3 install time
# ```
#
# ## Cache
#
#
# To use an existing list job ids to download job postings to a local cache:
#
# ```sh
# mkdir -p downloads && cd !$
# cat ids.txt |
# while read id; do
#   test -e "$id" || wget -q "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/$id" -O "id"
#   sleep 10
# done
# ```
# 
# To reformat email addresses to TSV file:
#
# ```sh
# cat emails.txt | 
# gsed 's/^\(.\+\)\.\(.\+\)@\(.\+\)/\0\t\1\t\2/i; s/\t\(.\)/\t\u\1/g' > 
# email-first-last.tsv
#
#
# ## Facet search
#
#
# LinkedIn provides facet search. This section has examples.
#
# Time:
#
#   * f_TPR=r86400 = Past 24 hours
#
#   * f_TPR=r604800 = Past week
#
# Geography:
#
#   * geoId=102448103 = Los Angeles, CA, US
#
#   * geoId=102571732 = New York, NY, US
#
#   * geoId=102277331 = San Francisco, CA, US
#
# Distance:
#
#   * distance=10 = 10 miles (16 km)
#
#   * distance=100 = 100 miles (160 km)
#
# Features:
#
#   * f_LF=f_JIYN = Jobs In Your Network
#
#   * f_LF=f_FCE = Fair Chance Employer
#
# Sort:
#
#   * sortBy=DD = Recency
#
#   * sortBy=R = Relevance
#
#
# ## How to fetch jobs' views
#
# Example code:
#
#     cat job_ids.txt |
#     while read x; do
#         curl -sSL "https://linkedin.com/jobs/view/$x" -o "$x.html"
#         sleep 1
#     done
#
#
# Example code to extract email addresses:
#
#     cat *.html | grep-email-addresses
#
#
# ## Future
#
#
# LinkedIn URLs that we may want to use in the future:
#
#   * https://www.linkedin.com/checkpoint/lg/login?...
#
#   * ... (for security challenge)
#
##

import argparse
import datetime
import errno
import logging
import numpy
import os
import pathlib
import random
import re
import selenium
import sys
import textwrap
import time
import traceback
import unittest
import urllib

from abc import ABC
from contextlib import contextmanager
from dataclasses import dataclass
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions
from selenium.common.exceptions import NoAlertPresentException
from selenium.common.exceptions import NoSuchElementException
from selenium.common.exceptions import StaleElementReferenceException
from selenium.common.exceptions import TimeoutException
from typing import List

##
#
# Data class section
#
##

@dataclass
class Job:
    id: int
    description: str = ""

    def __str__(self):
        return f'{self.id} {self.description}'

##
#
# Global
#
##

driver = None  # Selenium Chrome web driver
online = True  # True means use online real site; False means use offline local cache

##
#
# Log
#
##

class LogFormatter(logging.Formatter):
    """Log formatter that makes an exception into one line"""

    def format(self, record):
        result = super().format(record)
        if record.exc_text:
            result = result.replace("\n", "")
        return result
 
    def formatException(self, exc_info):
        result = super().formatException(exc_info)
        return repr(result)

def ini_logger():
    handler = logging.StreamHandler()
    formatter = LogFormatter(logging.BASIC_FORMAT)
    handler.setFormatter(formatter)
    logger = logging.getLogger()
    logger.addHandler(handler)
    logger.setLevel(os.environ.get("LOGLEVEL", "INFO"))
    return logger

L = ini_logger()

##
#
# System
#
##

def app_path():
    return pathlib.Path('linkedin-jobs-search-web-crawler')

def cache_home():
    return pathlib.Path(os.environ.get('XDG_CACHE_HOME', os.path.join(os.environ.get('HOME'), '.cache')))

def cache_dir():
    return cache_home() / app_path()

def ini_cache_dir():
    dir = cache_dir()
    dir.mkdir(parents=True, exist_ok=True)
    if not os.path.isdir(dir):
        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), dir)
    return dir

##
#
# Language
#
##

def each(function, iterable):
    for element in iterable:
        function(element)

def sleepy(seconds = 10.0):
    time.sleep(random.random() * seconds)

def now_id():
    return datetime.datetime.now().strftime("%Y%m%d%H%M%S%f")

##
#
# Data store
#
##

db = {'jobs': {}}  # Store of global data for lookups

def db_get(key, id):
    return db[key][id]

def db_set(key, id, object):
    db[key][id] = object

def db_dump():
    for key in db.keys():
        for id in db[key].keys():
            print(db_get(key, id))
            
##
#
# Selenium extras
#
##

# Credit: http://www.obeythetestinggoat.com/how-to-get-selenium-to-wait-for-page-load-after-a-click.html
def link_is_stale(link):
    try:
        link.find_elements_by_id('x') # poll the link with an arbitrary call
        return False
    except StaleElementReferenceException:
        return True

# Credit: http://www.obeythetestinggoat.com/how-to-get-selenium-to-wait-for-page-load-after-a-click.html
def link_click_fresh(link):
    link.click()
    wait_for(link_has_gone_stale(link))

def map_element_to_attribute(element, attribute):
    return element.get_attribute(attribute)

def map_element_to_attribute_list(element, attribute):
    return map(lambda x: map_element_to_attribute(x, attribute), element.find_elements_by_xpath('./*[@' + attribute + ']'))

def save_page(driver):
    file_name = os.path.join(cache_dir(), now_id() + '.html')
    with open(file_name, 'wb') as f:
        f.write(driver.page_source.encode('utf-8'))
 
##
#
# Selenium expectations
#
##

class expect_current_url_starts_with(object):
    """An expectation for checking that the current URL starts with text.

    Example: wait until the current URL starts with 'https://example.com'

        wait = WebDriverWait(driver, 10)
        element = wait.until(expect_current_url_starts_with('https://example.com'))

    text - any text
    """
    def __init__(self, text):
        self.text = text

    def __call__(self, driver):
        """Return true iff the current URL starts with the text."""
        return driver.current_url.startswith(self.text)

# Credit: https://selenium-python.readthedocs.io/waits.html
class expect_element_has_css_class(object):
    """An expectation for checking that an element has a particular css class.

    Example: wait until an element with id='myId' has CSS class 'myClass':

        wait = WebDriverWait(driver, 10)
        element = wait.until(expect_element_has_css_class((By.ID, 'myId'), 'myClass')

    locator - used to find the element
    css_class - a CSS class name
    returns the WebElement once it has the particular css class
    """
    def __init__(self, locator, css_class):
        self.locator = locator
        self.css_class = css_class

    def __call__(self, driver):
        element = driver.find_element(*self.locator)   # Finding the referenced element
        if self.css_class in element.get_attribute("class"):
            return element
        else:
            return False

# Credit: https://www.fomfus.com/articles/make-selenium-wait-for-anything-you-want-before-continuing
class expect_element_by_css_selector(object):
    """An expectation for checking that an element exists.

    Example: wait until an element exists with CSS selector 'mySelector':

        wait = WebDriverWait(driver, 10)
        element = wait.until(expect_element_expect_element_by_css_selector('mySelector'))

    css_selector - a CSS selector
    returns the WebElement once it has the particular css class
    """
    def __init__(self, css_selector):
        self.css_selector = css_selector

    def __call__(self, driver):
        """Search for element; return true iff found."""
        try:
            driver.find_elements_by_css_selector(self.css_selector)
            return True
        except NoSuchElementException:
            return False

# Credit: https://www.fomfus.com/articles/make-selenium-wait-for-anything-you-want-before-continuing
class expect_elements_by_css_selector(object):
    """An expectation for checking that an element exists "number" times.

    Example: wait until an element with CSS selector 'mySelector' exists 3 times:

        wait = WebDriverWait(driver, 10)
        element = wait.until(expect_element_expect_element_by_css_selector('mySelector', 3))

    css_selector - a CSS selector
    returns the WebElement once it has the particular css class
    """
    def __init__(self, css_selector, number):
        self.css_selector = css_selector
        self.number = number

    def __call__(self, driver):
        """Search for element, and return true when found self.number times."""
        try:
            found = len(driver.find_elements_by_css_selector(self.css_selector))
        except NoSuchElementException:
            found = 0

        return found == self.number

##
#
# Command line parser
#
##

def create_parser():
    parser = argparse.ArgumentParser(description="LinkedIn jobs search to JSON")
    parser.add_argument('--log-level', choices=('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'), help='log level; this can also be set by env var LOGLEVEL')
    parser.add_argument('--query',type=str, help='jobs search query, using encoded format; this overrides all other query args')
    parser.add_argument('--time', type=str, help='query time range for past searches, such as "day", "week", or "r000000" for seconds')
    parser.add_argument('--geo', type=str, help='query geography code, such as "newyorkcity" meaning New York City, NY, US')
    parser.add_argument('--geo-id', type=int, help='query geography id, such as 102571732 meaning New York City')
    parser.add_argument('--distance', type=int, help='query distance, such as 10 meaning within 10 kilomeers or miles')
    parser.add_argument('--fair-chance-employer', action="store_true", help='query fair chance employer')
    parser.add_argument('--jobs-in-your-network', action="store_true", help='query jobs in your network')
    return parser

##
#
# Selenium driver
#
##

DRIVER_WINDOW_WIDTH = 1680  # 1680 is Firefox full width on macOS MacBook Pro Retina 13" 
DRIVER_WINDOW_HEIGHT = 4096  # 4096 is arbitrarily large height to mitigate infinite scroll

def create_driver():
    return create_driver_with_firefox()

def create_driver_with_chrome():
    options = webdriver.chrome.options.Options()
    options.add_argument("--disable-extensions")
    options.add_argument(f"--window-size={DRIVER_WINDOW_WIDTH},{DRIVER_WINDOW_HEIGHT}")
    driver_path = "/usr/local/bin/chromedriver"
    driver = webdriver.Chrome(driver_path, options=options)
    return driver

def create_driver_with_firefox():
    options = webdriver.FirefoxOptions()
    options.add_argument(f"--width={DRIVER_WINDOW_WIDTH}")
    options.add_argument(f"--height={DRIVER_WINDOW_HEIGHT}")
    driver = webdriver.Firefox(options=options)
    return driver

##
#
# Environments for production, development, test, etc.
#
##

env = None

class Env(ABC):

    def url_base(self):
        pass

    def url_login(self):
        pass

    def url_checkpoint_challenge(self):
        pass

    def url_feed(self):
        pass

    def url_jobs_search_by_query_string(self, query_string):
        pass

    def url_jobs_search_by_id(self, job_id):
        pass

class EnvProduction(Env):

    def url_base(self):
        return 'https://linkedin.com'

    def url_login(self):
        return self.url_base() + '/login'

    def url_checkpoint_challenge(self):
        return self.url_base() + '/checkpoint/challenge'

    def url_feed(self):
        return self.url_base() + '/feed'

    def url_jobs_search_by_query_string(self, query_string):
        return self.url_base() + '/jobs/search?' + query_string
    
    def url_jobs_search_by_id(self, job_id):
        return self.url_base() + '/jobs/search?' + urllib.parse.urlencode({"currentJobId": id})

class EnvDevelopment(Env):

    def url_base(self):
        return 'http://0.0.0.0:8000'

    def url_login(self):
        return self.url_base() + '/login/index.html'

    def url_feed(self):
        return self.url_base() + '/feed/index.html'

    def url_checkpoint_challenge(self):
        return self.url_base() + '/checkpoint/challenge/index.html'

    def url_jobs_search_by_query_string(self, query_string):
        return self.url_base() + f'/jobs/search/query/index.html'

    def url_jobs_search_by_id(self, job_id):
        return self.url_base() + '/jobs/search/id/index.html'
##
#
# Web interaction
#
##

def go_home():
    driver.get(env.url_base())

def go_login(username, password):
    driver.get(env.url_login())
    form = driver.find_element_by_css_selector("form.login__form")
    form.find_element_by_css_selector("input#username").send_keys(username)
    form.find_element_by_css_selector("input#password").send_keys(password)
    form.find_element_by_xpath("//button[@type='submit']").click()

def go_security_verification():
    try:
        WebDriverWait(driver,10).until(expect_current_url_starts_with(env.url_checkpoint/challenge()))
        form = driver.find_element_by_css_selector('form#two-step-challenge')
        form.find_element_by_css_selector('input#input__phone_verification_pin').send_keys('0')
        WebDriverWait(driver,600).until(expect_current_url_starts_with(env.url_feed()))
    except TimeoutException:
        pass

def go_jobs_search_by_query_string(query_string):
    driver.get(env.url_jobs_search_by_query_string(query_string))
    save_page(driver)

def go_jobs_search_by_id(job_id):
    driver.get(env.url_jobs_search_by_id(job_id))

# def find_job_list():
#     L.debug("find_job_list")
#     element = driver.find_element_by_css_selector("ul.jobs-search-results__list")
#     if element == None:
#         L.error("find_job_list element:None")
#         return None
#     L.debug("find_job_list OK")
#     return element

# def find_job_list_items():
#     L.debug("find_job_list_items")
#     elements = find_job_list().find_elements_by_tag_name("li")
#     if elements == None:
#         L.error("find_job_list_items elements:None")
#         return None
#     L.debug(f"find_job_list_items elements len:{len(elements)}")
#     return elements

def find_job_ids():
    L.debug("find_job_ids")
    elements = driver.find_elements_by_xpath("//a[contains(@href, '/jobs/view/')]")
    L.info(f"find_job_ids len(elements):{len(elements)}")
    job_hrefs = list(map(lambda x: x.get_attribute("href"), elements))
    L.info(f"find_job_ids len(job_hrefs):{len(job_hrefs)}")
    job_ids = list(set(map(lambda x: int(re.sub(r'.*/jobs/view/(\d+).*', r'\1', x)), job_hrefs)))
    L.info(f"find_job_ids len(job_ids):{len(job_ids)}")
    for i in job_ids:
        print(f"job_id:{i}")
    return job_ids

# def find_job_ids_old():
#     L.debug("find_job_ids")
#     items = find_job_list_items()
#     if items == None:
#         L.error("find_job_ids items:None")
#         return None
#     L.debug("find_job_ids items OK")
#     L.debug(f"find_job_ids items len:{len(items)}")
#     L.debug(items[0].get_attribute("outerHTML"))
#     job_ids = list(filter(None, map(map_job_list_item_to_job_id, items)))
#     L.debug("find_job_ids job_ids", *job_ids)
#     return job_ids

# def map_job_list_item_to_job_id(job_list_item):
#     L.debug("map_job_list_item_to_job_id")
#     if not job_list_item:
#         L.error("map_job_list_item_to_job_id job_list_item:falsey")
#         return None
#     job_id = None
#     try:
#         elements = job_list_item.find_elements_by_tag_name('div')
#         if elements == None:
#             L.error("map_job_list_item_to_job_id elements:None")
#             html = job_list_item.get_attribute("outerHTML")
#             if html:
#                 L.error(f"map_job_list_item_to_job_id elements:None outerHTML:{html}")
#             else:
#                 L.error(f"map_job_list_item_to_job_id elements:None outerHTML:falsey")
#             return None
#         elif len(elements) == 0:
#             L.error("map_job_list_item_to_job_id len(elements):0")
#             html = job_list_item.get_attribute("outerHTML")
#             if html:
#                 L.error(f"map_job_list_item_to_job_id len(elements):0 outerHTML:{html}")
#             else:
#                 L.error(f"map_job_list_item_to_job_id len(elements):0 outerHTML:falsey")
#             return None
#         else:
#             L.debug("map_job_list_item_to_job_id elements len:{len(elements)}")
#             div = elements[0]
#             urn = div.get_attribute('data-job-id')
#             job_id = int(urn.split(':')[-1])
#             L.debug("map_job_list_item_to_job_id job_id:", job_id)
#     except StaleElementReferenceException as e:
#         L.exception("map_job_list_item_to_job_id", e)
#     return job_id

def find_job_description():
    return driver.find_element_by_class_name('results__detail-view') \
                 .find_element_by_class_name('description__text--rich')

def find_jobs_search_pagination_list():
    return driver.find_element_by_css_selector('ul.artdeco-pagination__pages')

def find_jobs_search_pagination_list_items():
    return find_jobs_search_pagination_list().find_elements_by_css_selector('li.artdeco-pagination__indicator--number')

##
#
# Control
#
##

def scan_jobs(query_string):
    for start in range(0, 200, 15):
        L.debug(f'==== loop start:{start} =====')
        go_jobs_search_by_query_string(query_string + f'&start={start}')
        ids = find_job_ids()
        jobs = list(map(lambda x: Job(x), ids))
        for job in jobs:
            db_set('jobs', job.id, job)
        sleepy(60)

def print_job_description():
    pass
    # description = find_job_description()
    # html = description.get_attribute('innerHTML')
    # print(html)

##
#
# Args
#
##

def args_time_to_pair(args):
    if args.time:
        if args.time == 'day':
            return ('f_TPR', 'r86400')
        elif args.time == 'week':
            return ('f_TPR', 'r604800')
        else:
            return ('f_TPR', args.time)
    return None

def args_geo_to_pair(args):
    if args.geo:
        if args.geo == 'losangeles':
            return ('geoId', 102448103)
        elif args.geo == 'newyorkcity':
            return ('geoId', 102571732)
        elif args.geo == "sanfrancisco":
            return ('geoId', 102277331)
        elif args.geo == "chicago":
            return ('geoId', 103112676)
        elif args.geo == "houston":
            return ('geoId', 103743442)
        elif args.geo == "philadelphia":
            return ('geoId', 104937023)
        else:
            return ('geoId', int(args.geo))
    return None

def args_geo_id_to_pair(args):
    if args.geo_id:
        return ('geoId', args.geo_id)
    return None

def args_distance_to_pair(args):
    if args.distance:
        return ('distance', args.distance)
    return None

def args_linkedin_features_to_pair(args):
    features = []
    if args.fair_chance_employer:
        features.append('f_FCE')
    if args.jobs_in_your_network:
        features.append('f_JIYN')
    if features:
        return ('f_LF', ",".join(features))                
    return None

def args_to_query_pairs(args):
    pairs = []
    
    pair = args_time_to_pair(args)
    if pair: pairs.append(pair)
    
    pair = args_geo_to_pair(args)
    if pair: pairs.append(pair)
    
    pair = args_geo_id_to_pair(args)
    if pair: pairs.append(pair)

    pair = args_distance_to_pair(args)
    if pair: pairs.append(pair)
    
    pair = args_linkedin_features_to_pair(args)
    if pair: pairs.append(pair)

    return pairs

def args_to_query_string(args):
    if args.query:
        return args.query
    else:
        return urllib.parse.urlencode(args_to_query_pairs(args))

##
#
# Main
#
##

def cli_main():
    args = parser.parse_args()
    global driver
    driver = create_driver()
    username = os.environ["LINKEDIN_USERNAME"]
    password = os.environ["LINKEDIN_PASSWORD"]
    go_login(username, password) and sleepy() 
    #go_security_verification()
    query_string = args_to_query_string(args)
    if query_string:
        scan_jobs(query_string)
        db_dump()
    else:
        L.error("query missing")

##
#
# Test
#
##

class TestDB(unittest.TestCase):

    def test_db_get(self):
        db_set('jobs', 'id', 'object')
        self.assertEqual(db_get('jobs', 'id'), 'object')

    def test_db_set(self):
        db_set('jobs', 'id', 'object')
        self.assertEqual(db_get('jobs', 'id'), 'object')

class TestAll(unittest.TestCase):

    def test_each(self):
        pass

    def test_sleepy(self):
        sleepy(0)

    def test_link_is_stale(self):
        pass

    def test_link_click_fresh(self):
        pass

class TestParseArgs(unittest.TestCase):

    def setUp(self):
        self.parser = create_parser()

    def test_query(self):
        args = self.parser.parse_args(['--query', 'foo'])
        self.assertEqual(args.query, 'foo')
        
    def test_time(self):
        args = self.parser.parse_args(['--time', 'r123'])
        self.assertEqual(args.time, 'r123')

    def test_geo__with_newyorkcity(self):
        args = self.parser.parse_args(['--geo', 'newyorkcity'])
        self.assertEqual(args.geo, 'newyorkcity')

    def test_geo_id(self):
        args = self.parser.parse_args(['--geo-id', '102571732'])
        self.assertEqual(args.geo_id, 102571732)

    def test_distance(self):
        args = self.parser.parse_args(['--distance', '10'])
        self.assertEqual(args.distance, 10)

    def test_fair_chance_employer(self):
        args = self.parser.parse_args(['--fair-chance-employer'])
        self.assertEqual(args.fair_chance_employer, True)

    def test_jobs_in_your_network(self):
        args = self.parser.parse_args(['--jobs-in-your-network'])
        self.assertEqual(args.jobs_in_your_network, True)

class TestArgsX(unittest.TestCase):

    def setUp(self):
        self.parser = create_parser()

    def test_args_time_to_pair__with_id(self):
        args = self.parser.parse_args(['--time', 'r123'])
        self.assertEqual(args_time_to_pair(args), ('f_TPR', 'r123'))

    def test_args_time_to_pair__with_day(self):
        args =  self.parser.parse_args(['--time', 'day'])
        self.assertEqual(args_time_to_pair(args), ('f_TPR', 'r86400'))

    def test_args_time_to_pair__with_week(self):
        args =  self.parser.parse_args(['--time', 'week'])
        self.assertEqual(args_time_to_pair(args), ('f_TPR', 'r604800'))

    def test_args_geo_to_pair__with_newyorkcity_key(self):
        args = self.parser.parse_args(['--geo', 'newyorkcity'])
        self.assertEqual(args_geo_to_pair(args), ('geoId', 102571732))

    def test_args_geo_to_pair__with_newyorkcity_id(self):
        args =  self.parser.parse_args(['--geo', '102571732'])
        self.assertEqual(args_geo_to_pair(args), ('geoId', 102571732))

    def test_args_distance_to_pair(self):
        args =  self.parser.parse_args(['--distance', '10'])
        self.assertEqual(args_distance_to_pair(args), ('distance', 10))

    def test_args_linkedin_features_to_pair__with_fair_chance_employer(self):
        args =  self.parser.parse_args(['--fair-chance-employer'])
        self.assertEqual(args_linkedin_features_to_pair(args), ('f_LF', 'f_FCE'))

    def test_args_linkedin_features_to_pair__with_jobs_in_your_network(self):
        args =  self.parser.parse_args(['--jobs-in-your-network'])
        self.assertEqual(args_linkedin_features_to_pair(args), ('f_LF', 'f_JIYN'))

    def test_args_linkedin_features_to_pair__with_multiples(self):
        args =  self.parser.parse_args(['--fair-chance-employer', '--jobs-in-your-network'])
        self.assertEqual(args_linkedin_features_to_pair(args), ('f_LF', 'f_FCE,f_JIYN'))
        
    def test_args_to_query_pairs(self):
        args =  self.parser.parse_args(['--time', 'day', '--geo', 'ny', '--distance', '10', '--fair-chance-employer', '--jobs-in-your-network'])
        self.assertEqual(args_to_query_pairs(args), [('f_TPR', 'r86400'), ('geoId', 102571732), ('distance', 10), ('f_LF', 'f_FCE,f_JIYN')])

    def test_args_to_query_string_with_text(self):
        args =  self.parser.parse_args(['--query', 'foo'])
        self.assertEqual(args_to_query_string(args), 'foo')

    def test_args_to_query_string_with_pairs(self):
        args =  self.parser.parse_args(['--time', 'day', '--geo', 'ny', '--distance', '10', '--fair-chance-employer', '--jobs-in-your-network'])
        self.assertEqual(args_to_query_string(args), 'f_TPR=r86400&geoId=102571732&distance=10&f_LF=f_FCE%2Cf_JIYN')

class TestSeleniumMaps(unittest.TestCase):

    def test_map_element_to_attribute(self):
        html = '<html><body><p id="alpha" name="bravo"></p></body></html>'
        driver.get("data:text/html;charset=utf-8," + html)
        element = driver.find_element_by_id('alpha')
        self.assertEqual(map_element_to_attribute(element, 'name'), 'bravo')

    def test_map_element_to_attribute_list(self):
        html = '<html><body id="body"><p id="alpha" name="bravo"></p><p id="charlie" name="delta"></p></body></html>'
        driver.get("data:text/html;charset=utf-8," + html)
        element = driver.find_element_by_id('body')
        self.assertEqual(list(map_element_to_attribute_list(element, 'name')), ['bravo', 'delta'])

class TestSeleniumExpectations(unittest.TestCase):

    def test_expect_current_url_starts_with(self):
        pass
    
    def test_expect_element_has_css_class(self):
        pass

    def test_expect_element_by_css_selector(self):
        pass

    def test_expect_elements_by_css_selector(self):
        pass
    
class TestStartup(unittest.TestCase):

    def test_create_driver(self):
        pass

class TestEnv(unittest.TestCase):

    def test_url_base(self):
        self.assertEqual(env.url_base(), 'http://0.0.0.0:8000')

    def test_url_login(self):
        self.assertEqual(env.url_login(), 'http://0.0.0.0:8000/login/index.html')

    def test_url_checkpoint_challenge(self):
        self.assertEqual(env.url_checkpoint_challenge(), 'http://0.0.0.0:8000/checkpoint/challenge/index.html')

    def test_url_feed(self):
        self.assertEqual(env.url_feed(), 'http://0.0.0.0:8000/feed/index.html')

    def test_url_jobs_search_by_query_string(self):
        self.assertEqual(env.url_jobs_search_by_query_string('keywords=alpha+bravo'), 'http://0.0.0.0:8000/jobs/search/query/index.html')

    def test_url_jobs_search_by_query_string_with_start(self):
        self.assertEqual(env.url_jobs_search_by_query_string('keywords=alpha+bravo&start=25'), 'http://0.0.0.0:8000/jobs/search/query/index.html')

    def test_url_jobs_search_by_id(self):
        self.assertEqual(env.url_jobs_search_by_id(123), 'http://0.0.0.0:8000/jobs/search/id/index.html')

class TestLinkedInWebInterations(unittest.TestCase):

    DATA = "data:text/html;charset=utf-8," 

    JOB_HTML = textwrap.dedent('''\
    <html>
        <body>
            <ul class="jobs-search-results__list">
                <li><div data-job-id="urn:li:x:123">Alpha</div></li>
                <li><div data-job-id="urn:li:x:456">Bravo</div></li>
                <li><div data-job-id="urn:li:x:789">Bravo</div></li>
            </ul>
        </body>
    </html>
    ''')

    JOB_IDS = [123, 456, 789]

    def test_go_home(self):
        pass

    def test_go_login(self):
        pass

    def test_go_security_verification(self):
        pass

    def test_go_jobs_search(self):
        pass

    def test_go_job(self):
        pass

    def test_find_job_list(self):
        driver.get(self.DATA + self.JOB_HTML)
        self.assertIsNotNone(find_job_list())

    def test_find_job_list_items(self):
        driver.get(self.DATA + self.JOB_HTML)
        self.assertEqual(len(find_job_list_items()), 3)

    def test_find_job_ids(self):
        driver.get(self.DATA + self.JOB_HTML)
        self.assertEqual(find_job_ids(), self.JOB_IDS)

    def test_find_job_description(self):
        pass

    def test_map_job_list_item_to_job_id(self):
        pass

    def test_find_jobs_search_pagination_list(self):
        pass

    def find_jobs_search_pagination_list_items(self):
        pass

global parser
parser = create_parser()
args = parser.parse_args()
if args.log_level:
    L.setLevel(args.log_level)
ini_cache_dir()

if __name__ == '__main__':
    driver = create_driver()
    os_environ_env = os.environ.get('ENV', 'development')
    if os_environ_env == 'development':
        env = EnvDevelopment()
    elif os_environ_env == 'test':
        env = EnvDevelopment()
    elif os_environ_env == 'production':
        env = EnvProduction()
    if os_environ_env == 'test':
        unittest.main()
    else:
        cli_main()

